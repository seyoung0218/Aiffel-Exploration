{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트14 - 한국어 데이터로 챗봇 만들기\n",
        "# Step1. Import Library"
      ],
      "metadata": {
        "id": "TMGFLKVZaDZB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "BTGqqYVPZ9ET"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step2. Import Data\n",
        "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다."
      ],
      "metadata": {
        "id": "hBWNbB-Q8hE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Exploration_Data/ex14/ChatbotData .csv')\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "OR4S_CIK8gQW",
        "outputId": "0fcf8c89-dd0d-4e01-ffe5-267e380b4fff"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11823, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d738d2a8-c26a-46f7-bbaf-ba39a8d3b3f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d738d2a8-c26a-46f7-bbaf-ba39a8d3b3f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d738d2a8-c26a-46f7-bbaf-ba39a8d3b3f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d738d2a8-c26a-46f7-bbaf-ba39a8d3b3f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문과 대화를 분리시켜 저장합니다.\n",
        "data_Q = data['Q']\n",
        "data_A = data['A']\n",
        "\n",
        "print('Q:',data_Q[5])\n",
        "print('A:',data_A[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFw5471GMDbB",
        "outputId": "5a1e34cb-c23e-4204-f2b6-53395b951f99"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: SD카드 망가졌어\n",
            "A: 다시 새로 사는 게 마음 편해요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step3. Data Preprocessing\n",
        "## 1.중복치, 결측치 확인"
      ],
      "metadata": {
        "id": "Kuy75z4sNIpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 개수세기\n",
        "print('Q:',data_Q.isnull().sum())\n",
        "print('A:',data_A.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4eGFsU1NMLm",
        "outputId": "ed51d856-db87-4345-e19f-bee7faa161e8"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 0\n",
            "A: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복치 개수세기\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPs-ETkNgRP",
        "outputId": "cb3bc1b1-5ba4-4271-f43d-7dd13e574c95"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.구두점 분리 함수\n",
        "구두점과 단어사이에 거리를 만들어 토크나이징하는 일에 방해가 되지 않도록합니다.\n"
      ],
      "metadata": {
        "id": "dpi9I73SOJI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  \n",
        "  # 단어와 구두점(punctuation)사이의 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        " \n",
        "  return sentence"
      ],
      "metadata": {
        "id": "B0oh5xhWOEOF"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.전처리함수 적용\n",
        "전처리함수를 거친다음 전부 리스트로 저장해줍니다."
      ],
      "metadata": {
        "id": "UamuHqH6C6kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  questions.append(preprocess_sentence(data_Q[i]))\n",
        "  answers.append(preprocess_sentence(data_A[i]))"
      ],
      "metadata": {
        "id": "eRtMq8vlAPLO"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9HigI6GC9YK",
        "outputId": "640cb7fc-599c-40dd-9784-26c6756f82f8"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 ! ', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcVA5QseBu6i",
        "outputId": "4e838af8-52ec-4feb-a22d-6373bb4061bd"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하루가 또 가네요 . ',\n",
              " '위로해 드립니다 . ',\n",
              " '여행은 언제나 좋죠 . ',\n",
              " '여행은 언제나 좋죠 . ',\n",
              " '눈살이 찌푸려지죠 . ']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "구두점 양쪽으로 전부 공백이 생긴걸 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "iC0VUbl-EWP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 단어장 만들기\n",
        "토크나이저는 tensorflow datasets SubwordTextEncoder로 사용합니다. \n",
        "\n",
        "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장을 만들어보겠습니다. 단어장을 만들때는 질문과 답변 데이터셋을 모두 사용하여 만듭니다."
      ],
      "metadata": {
        "id": "YqsvAgSZHl1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문과 답변 데이터셋에 대한 단어장 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=10000)"
      ],
      "metadata": {
        "id": "8hafJP7gEOiK"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이때 디코더의 문장 생성 과정에서 사용할 '시작토큰'과 '종료토큰'에 대해서도 임의로 단어장에 추가하여서 정수를 부여해 줍니다. 이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰수를 부여하겠습니다."
      ],
      "metadata": {
        "id": "TybUCpH2JCKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "print('시작토큰의 번호:', [tokenizer.vocab_size])\n",
        "print('종료토큰의 번호:', [tokenizer.vocab_size + 1])\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print('단어장의 크기:', VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tkhhrp1I7y_",
        "outputId": "7c5140f6-347a-425d-ec3d-eabc7a2a5b98"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시작토큰의 번호: [10106]\n",
            "종료토큰의 번호: [10107]\n",
            "단어장의 크기: 10108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 각 단어를 고유한 정수로 인코딩 & 패딩\n",
        "위에서 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 단어장을 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다.\n",
        "\n",
        "예를 들어서 22번째 샘플을 사용해 변환결과를 보겠습니다."
      ],
      "metadata": {
        "id": "al5kPJXKK0Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFhS4fEKKV2Q",
        "outputId": "9c389768-247c-488c-96ee-2eef49948098"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [9787, 2193, 3608]\n",
            "정수 인코딩 후의 21번째 답변 샘플: [2070, 6543, 7, 5460, 116, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이처럼 각 단어에 고유한 정수가 부여된 단어장을 기준으로 단어시퀀스가 정수시퀀스로 인코딩된 결과를 확인할 수 있습니다. 위의 결과와 마찬가지로 질문과 답변셋에 대해서 전부 정수인코딩을 수행합니다. 이와 동시에 문장의 최대 길이를 정하고, 해당 길이로 패딩을 수행합니다."
      ],
      "metadata": {
        "id": "UrkJ3XVZMlkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# questions와 answers의 문장 길이 분포리스트\n",
        "questions_len = [len(s.split()) for s in questions]\n",
        "answers_len = [len(s.split()) for s in answers]\n",
        "\n",
        "print('questions의 최소길이: {}'.format(np.min(questions_len)))\n",
        "print('questions의 최대길이: {}'.format(np.max(questions_len)))\n",
        "print('questions의 평균길이: {}'.format(np.mean(questions_len)))\n",
        "print('answers의 최소길이: {}'.format(np.min(answers_len)))\n",
        "print('answers의 최대길이: {}'.format(np.max(answers_len)))\n",
        "print('answers의 평균길이: {}'.format(np.mean(answers_len)))\n",
        "\n",
        "plt.title('questions')\n",
        "plt.hist(questions_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('answers')\n",
        "plt.hist(answers_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "j1V3FyVYNQ_B",
        "outputId": "2e34bf14-7f59-4b7d-d29d-85b2e02404d4"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "questions의 최소길이: 1\n",
            "questions의 최대길이: 16\n",
            "questions의 평균길이: 3.9402858834475176\n",
            "answers의 최소길이: 1\n",
            "answers의 최대길이: 24\n",
            "answers의 평균길이: 4.71589275141673\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcA0lEQVR4nO3de7xXdZ3v8ddb8jZqIUIcRHRrMpVWkiHWCQtzvDcHfRzzMpVoFNXBtDPWCauT2AwTlWljNRaMJJrJcEZNTvAIyRDGKRVQhmsed1wGtggkiqhFAp/zx/ruXG73ZS3Ya/9+e+/38/FYj99an3X77MWP/dnfdfkuRQRmZmZl7FfrBMzMrPtx8TAzs9JcPMzMrDQXDzMzK83Fw8zMSnPxMDOz0lw8zMysNBcPMzMrzcXDrJuS9IZa52C9l4uHWSskTZD0O0k7JK2SdGGKXyHpYUk3SnpO0lpJ5+bWu0LSmrTeWkkfTfH1kt6Txj8qKSSdmKbHSvpZGt8vt+9nJc2U1C/Na0jrjZX0n8CvJB0k6Sdp2eclLZI0sIsPl/VCLh5mrfsdcBrwJuAG4CeSBqV5pwJPAv2BbwG3KXMIcAtwbkQcBvxXYGlaZwEwKo1/EFgDfCA3vSCNfw64IMWOBJ4DftAitw8CbwfOBsakHIcARwCfAf6wbz+6WcdcPMxaERH/JyKejog9EfEvwFPAiDR7fURMjYjdwHRgEND81/4e4B2SDo6ITRGxMsUXkP3Sh6wofSM3nS8enwG+EhEbI2InMBG4qMUpqokR8VJE/AF4haxoHB8RuyNiSUS80HlHwqx1Lh5mrZB0uaSl6VTQ88A7yFoaAM80LxcRL6fRQyPiJeASsgKwSdJsSW9L8xcAp6XWSx9gJvB+SQ1kLYfmFsoxwH25/a4GdvNqcQLYkBu/E5gLzJD0tKRvSdq/Ew6BWbtcPMxakHQMMBW4CjgiIvoCKwB1tG5EzI2IM8laI79N2yEiGoGXyU5LLUytg2eAccDDEbEnbWID2WmvvrnhoIhoyu8mt79XIuKGiDiB7DTZh4HL9+XnNyvCxcPs9Q4h+wW9FUDSlWQtj3ZJGihpdLr2sRN4kew0VrMFZAWp+RTVQy2mAX4ITEoFDEkDJI1uZ5+nS3qnpD7AC2Snsfa0tbxZZ3HxMGshIlYB3wF+A2wG3gn8e4FV9wP+Fnga2EZ2LeOzufkLgMOAhW1MA/wjMAt4QNIO4BGyC/Rt+S/Av5IVjtVpm3cWyNVsn8gvgzIzs7Lc8jAzs9JcPMzMrDQXDzMzK83Fw8zMSuuRHav1798/Ghoaap2GmVm3smTJkt9HxIAiy/bI4tHQ0MDixYtrnYaZWbciaX3RZX3ayszMSnPxMDOz0lw8zMysNBcPMzMrzcXDzMxKc/EwM7PSXDzMzKw0Fw8zMyvNxcPMzErrkU+Y91QNE2a3OW/d5PO7MBMz6+3c8jAzs9IqKx6SDpL0mKT/kLRS0g0pfqykRyU1SvoXSQek+IFpujHNb8ht67oUf1LS2VXlbGZmxVTZ8tgJfCgiTgKGAedIei/wTeDmiDgeeA4Ym5YfCzyX4jen5ZB0AnApcCJwDvBPkvpUmLeZmXWgsuIRmRfT5P5pCOBDwL+m+HTggjQ+Ok2T5p8hSSk+IyJ2RsRaoBEYUVXeZmbWsUqveUjqI2kpsAWYB/wOeD4idqVFNgKD0/hgYANAmr8dOCIfb2Wd/L7GSVosafHWrVur+HHMzCyptHhExO6IGAYcRdZaeFuF+5oSEcMjYviAAYXeZWJmZnupS+62iojngfnA+4C+kppvET4KaErjTcAQgDT/TcCz+Xgr65iZWQ1UebfVAEl90/jBwJnAarIiclFabAxwfxqflaZJ838VEZHil6a7sY4FhgKPVZW3mZl1rMqHBAcB09OdUfsBMyPi55JWATMk/T3wBHBbWv424E5JjcA2sjusiIiVkmYCq4BdwPiI2F1h3mZm1oHKikdELAPe3Up8Da3cLRURfwQ+0sa2JgGTOjtHMzPbO37C3MzMSnPxMDOz0lw8zMysNBcPMzMrzcXDzMxKc/EwM7PSXDzMzKw0Fw8zMyvNxcPMzEpz8TAzs9JcPMzMrDQXDzMzK83Fw8zMSnPxMDOz0lw8zMysNBcPMzMrzcXDzMxKc/EwM7PSXDzMzKw0Fw8zMyvNxcPMzEpz8TAzs9JcPMzMrDQXDzMzK83Fw8zMSquseEgaImm+pFWSVkq6JsUnSmqStDQN5+XWuU5So6QnJZ2di5+TYo2SJlSVs5mZFfOGCre9C7g2Ih6XdBiwRNK8NO/miLgxv7CkE4BLgROBI4FfSvrLNPsHwJnARmCRpFkRsarC3M3MrB2VFY+I2ARsSuM7JK0GBrezymhgRkTsBNZKagRGpHmNEbEGQNKMtKyLh5lZjXTJNQ9JDcC7gUdT6CpJyyRNk3R4ig0GNuRW25hibcVb7mOcpMWSFm/durWTfwIzM8urvHhIOhS4B/h8RLwA3Aq8BRhG1jL5TmfsJyKmRMTwiBg+YMCAztikmZm1ocprHkjan6xw3BUR9wJExObc/KnAz9NkEzAkt/pRKUY78W6lYcLsduevm3x+F2ViZrZvqrzbSsBtwOqIuCkXH5Rb7EJgRRqfBVwq6UBJxwJDgceARcBQScdKOoDsovqsqvI2M7OOVdnyeD/wcWC5pKUp9mXgMknDgADWAZ8GiIiVkmaSXQjfBYyPiN0Akq4C5gJ9gGkRsbLCvM3MrANV3m31MKBWZs1pZ51JwKRW4nPaW8/MzLqWnzA3M7PSXDzMzKy0Su+2sq7jO7nMrCu55WFmZqW5eJiZWWkuHmZmVpqLh5mZldZh8ZD0kdSlOpK+KuleSSdXn5qZmdWrIi2P/526VB8J/BVZlyO3VpuWmZnVsyLFY3f6PB+YEhGzgQOqS8nMzOpdkeLRJOlHwCXAHEkHFlzPzMx6qCJF4GKyTgnPjojngX7AFyvNyszM6lqHxSMiXga2ACNTaBfwVJVJmZlZfStyt9X1wJeA61Jof+AnVSZlZmb1rchpqwuB/wa8BBARTwOHVZmUmZnVtyLF408REWQvb0LSIdWmZGZm9a5I8ZiZ7rbqK+lTwC+BqdWmZWZm9azDLtkj4kZJZwIvAG8FvhYR8yrPzMzM6lah93mkYuGCYWZmQDvFQ9IO0nWOlrOAiIg3VpaVmZnVtTaLR0T4jiozM2tVodNWqRfdkWQtkYcj4olKszIzs7pW5CHBrwHTgSOA/sDtkr5adWJmZla/irQ8PgqcFBF/BJA0GVgK/H2ViZmZWf0q8pzH08BBuekDgaaOVpI0RNJ8SaskrZR0TYr3kzRP0lPp8/AUl6RbJDVKWpZ/4ZSkMWn5pySNKfcjmplZZytSPLYDKyXdLunHwArg+fSL/pZ21tsFXBsRJwDvBcZLOgGYADwYEUOBB9M0wLnA0DSMI71wSlI/4HrgVGAEcH1zwTEzs9ooctrqvjQ0e6jIhiNiE7Apje+QtBoYDIwGRqXFpqftfSnF70hdoTwiqa+kQWnZeRGxDUDSPOAc4O4ieZiZWecr8oT59H3diaQG4N3Ao8DAVFgAngEGpvHBwIbcahtTrK24mZnVSJG7rT4s6QlJ2yS9IGmHpBeK7kDSocA9wOcj4jXr5Ttc3FeSxklaLGnx1q1bO2OTZmbWhiLXPL4LjAGOiIg3RsRhRZ8ul7Q/WeG4KyLuTeHN6XQU6XNLijcBQ3KrH5VibcVfIyKmRMTwiBg+YMCAIumZmdleKlI8NgArUiuhMEkCbgNWR8RNuVmzyIoR6fP+XPzydNfVe4Ht6fTWXOAsSYenC+VnpZiZmdVIkQvm/wuYI2kBsLM52KIgtOb9wMeB5ZKWptiXgclk3byPBdaTvSMdYA5wHtAIvAxcmfazTdLfAYvScl9vvnhuZma1UaR4TAJeJHvW44CiG46Ih8k6UWzNGa0sH8D4NrY1DZhWdN9mZlatIsXjyIh4R+WZmJlZt1HkmsccSWdVnomZmXUbRYrHZ4FfSPrD3tyqa2ZmPU+RhwT9Xg8zM3uNou/zOJysz6k/d5AYEQurSsrMzOpbh8VD0ieBa8gezltK1snhb4APVZuamZnVqyLXPK4BTgHWR8TpZH1UPV9pVmZmVteKFI8/5l4EdWBE/BZ4a7VpmZlZPStyzWOjpL7Az4B5kp4jezLczMx6qSJ3W12YRidKmg+8CfhFpVmZmVldK9Il+1skHdg8CTQAf1FlUmZmVt+KXPO4B9gt6XhgCln36D+tNCszM6trRYrHnojYBVwIfC8ivggMqjYtMzOrZ0WKxyuSLiN798bPU2z/6lIyM7N6V6R4XAm8D5gUEWslHQvcWW1aZmZWz4rcbbUKuDo3vRb4ZpVJmZlZfSvS8jAzM3sNFw8zMyutzeIh6c70eU3XpWNmZt1Bey2P90g6EviEpMMl9csPXZWgmZnVn/YumP8QeBA4DlhC9nR5s0hxMzPrhdpseUTELRHxdmBaRBwXEcfmBhcOM7NerMitup+VdBJwWgotjIhl1aZlZmb1rEjHiFcDdwFvTsNdkj5XdWJmZla/irzP45PAqRHxEoCkb5K9hvZ7VSZmZmb1q8hzHgJ256Z389qL562vJE2TtEXSilxsoqQmSUvTcF5u3nWSGiU9KensXPycFGuUNKHYj2VmZlUq0vL4MfCopPvS9AXAbQXWux34PnBHi/jNEXFjPiDpBOBS4ETgSOCXkv4yzf4BcCawEVgkaVbqMsXMzGqkyAXzmyQ9BIxMoSsj4okC6y2U1FAwj9HAjIjYCayV1AiMSPMaI2INgKQZaVkXDzOzGirS8iAiHgce76R9XiXpcmAxcG1EPAcMBh7JLbMxxQA2tIif2tpGJY0DxgEcffTRnZSqmZm1pqv7troVeAswDNgEfKezNhwRUyJieEQMHzBgQGdt1szMWlGo5dFZImJz87ikqbz6cqkmstfbNjsqxWgnbmZmNdJuy0NSH0nzO2tnkvKvr70QaL4TaxZwqaQD08umhgKPAYuAoZKOlXQA2UX1WZ2Vj5mZ7Z12Wx4RsVvSHklviojtZTYs6W5gFNBf0kbgemCUpGFkfWOtAz6d9rNS0kyyC+G7gPERsTtt5ypgLtCHrKuUlWXyMDOzzlfktNWLwHJJ84CXmoMRcXXbq0BEXNZKuM1bfCNiEjCplfgcYE6BPM3MrIsUKR73psF6sIYJs9uct27y+V2YiZl1B0We85gu6WDg6Ih4sgtyMjOzOlekY8S/BpYCv0jTwyT5orWZWS9W5DmPiWRPez8PEBFL8YugzMx6tSLF45VW7rTaU0UyZmbWPRS5YL5S0t8AfSQNBa4Gfl1tWmZmVs+KtDw+R9bb7U7gbuAF4PNVJmVmZvWtyN1WLwNfSS+BiojYUX1aZmZWz4rcbXWKpOXAMrKHBf9D0nuqT83MzOpVkWsetwH/IyL+DUDSSLIXRL2rysTMzKx+Fbnmsbu5cABExMNk/U+ZmVkv1WbLQ9LJaXSBpB+RXSwP4BLgoepTMzOzetXeaauWL2q6PjceFeRiZmbdRJvFIyJO78pEzMys++jwgrmkvsDlQEN++Y66ZDczs56ryN1Wc4BHgOW4WxIzM6NY8TgoIv628kzMzKzbKHKr7p2SPiVpkKR+zUPlmZmZWd0q0vL4E/Bt4Cu8epdV4G7Zzcx6rSLF41rg+Ij4fdXJmJlZ91DktFUj8HLViZiZWfdRpOXxErBU0nyybtkB36prZtabFSkeP0uDmZkZUOx9HtO7IhEzM+s+irzPY62kNS2HAutNk7RF0opcrJ+keZKeSp+Hp7gk3SKpUdKyXKeMSBqTln9K0pi9/UHNzKzzFLlgPhw4JQ2nAbcAPymw3u3AOS1iE4AHI2Io8GCaBjgXGJqGccCtkBUbsg4ZTwVGANc3FxwzM6udDotHRDybG5oi4rvA+QXWWwhsaxEeDTSfBpsOXJCL3xGZR4C+kgYBZwPzImJbRDwHzOP1BcnMzLpYkY4RT85N7kfWEilyob01AyNiUxp/BhiYxgcDG3LLbUyxtuJmZlZDRYpA/r0eu4B1wMX7uuOICEmd9l4QSePITnlx9NFHd9ZmzcysFUXuturM93psljQoIjal01JbUrwJGJJb7qgUawJGtYg/1EaeU4ApAMOHD/fLqszMKlTktNWBwH/n9e/z+Ppe7G8WMAaYnD7vz8WvkjSD7OL49lRg5gL/kLtIfhZw3V7s18zMOlGR01b3A9uBJeSeMO+IpLvJWg39JW0ku2tqMjBT0lhgPa+e/poDnMerXaFcCRAR2yT9HbAoLff1iGh5Ed7MzLpYkeJxVESUvsMpIi5rY9YZrSwbwPg2tjMNmFZ2/2ZmVp0iz3n8WtI7K8/EzMy6jSItj5HAFZLWkp22Ellj4V2VZmZmZnWrSPE4t/IszMysWylyq+76rkjEzMy6jyLXPMzMzF7DxcPMzErb2z6qzP6sYcLsNuetm9xhH5pm1g255WFmZqW5eJiZWWkuHmZmVpqLh5mZlebiYWZmpfluq5Lau7MIfHeRmfUObnmYmVlpLh5mZlaai4eZmZXm4mFmZqW5eJiZWWkuHmZmVpqLh5mZlebiYWZmpbl4mJlZaS4eZmZWmouHmZmV5uJhZmal1aR4SFonabmkpZIWp1g/SfMkPZU+D09xSbpFUqOkZZJOrkXOZmb2qlq2PE6PiGERMTxNTwAejIihwINpGuBcYGgaxgG3dnmmZmb2GvV02mo0MD2NTwcuyMXviMwjQF9Jg2qRoJmZZWpVPAJ4QNISSeNSbGBEbErjzwAD0/hgYENu3Y0p9hqSxklaLGnx1q1bq8rbzMyo3cugRkZEk6Q3A/Mk/TY/MyJCUpTZYERMAaYADB8+vNS6ZmZWTk1aHhHRlD63APcBI4DNzaej0ueWtHgTMCS3+lEpZmZmNdLlxUPSIZIOax4HzgJWALOAMWmxMcD9aXwWcHm66+q9wPbc6S0zM6uBWpy2GgjcJ6l5/z+NiF9IWgTMlDQWWA9cnJafA5wHNAIvA1d2fcpmZpbX5cUjItYAJ7USfxY4o5V4AOO7IDUzMyuonm7VNTOzbqJWd1uZAdAwYXa789dNPr+LMjGzMtzyMDOz0lw8zMysNBcPMzMrzcXDzMxKc/EwM7PSXDzMzKw0Fw8zMyvNxcPMzEpz8TAzs9JcPMzMrDR3T2J1rb3uS9x1iVntuOVhZmaluXiYmVlpLh5mZlaai4eZmZXm4mFmZqW5eJiZWWkuHmZmVpqLh5mZleaHBK3H8gOGZtVx8TBrRXuFB1x8zHzayszMSnPxMDOz0rpN8ZB0jqQnJTVKmlDrfMzMerNucc1DUh/gB8CZwEZgkaRZEbGqiv11dL7brD378v3p6FqKr8VYvegWxQMYATRGxBoASTOA0UAlxcOsJ9rXwuO71yxPEVHrHDok6SLgnIj4ZJr+OHBqRFyVW2YcMC5NvhV4EugP/L6L061XPhYZH4eMj0PGxyHTfByOiYgBRVboLi2PDkXEFGBKPiZpcUQMr1FKdcXHIuPjkPFxyPg4ZPbmOHSXC+ZNwJDc9FEpZmZmNdBdisciYKikYyUdAFwKzKpxTmZmvVa3OG0VEbskXQXMBfoA0yJiZYFVp3S8SK/hY5Hxccj4OGR8HDKlj0O3uGBuZmb1pbuctjIzszri4mFmZqX12OLh7kwyktZJWi5pqaTFtc6nK0maJmmLpBW5WD9J8yQ9lT4Pr2WOXaGN4zBRUlP6XiyVdF4tc+wKkoZImi9plaSVkq5J8V71nWjnOJT6TvTIax6pO5P/R647E+CyqrozqWeS1gHDI6LXPQgl6QPAi8AdEfGOFPsWsC0iJqc/Kg6PiC/VMs+qtXEcJgIvRsSNtcytK0kaBAyKiMclHQYsAS4ArqAXfSfaOQ4XU+I70VNbHn/uziQi/gQ0d2divUhELAS2tQiPBqan8elk/2l6tDaOQ68TEZsi4vE0vgNYDQyml30n2jkOpfTU4jEY2JCb3sheHJweIoAHJC1JXbj0dgMjYlMafwYYWMtkauwqScvSaa0efaqmJUkNwLuBR+nF34kWxwFKfCd6avGwV42MiJOBc4Hx6RSGAZGds+15522LuRV4CzAM2AR8p7bpdB1JhwL3AJ+PiBfy83rTd6KV41DqO9FTi4e7M0kioil9bgHuIzul15ttTud8m8/9bqlxPjUREZsjYndE7AGm0ku+F5L2J/uFeVdE3JvCve470dpxKPud6KnFw92ZAJIOSRfEkHQIcBawov21erxZwJg0Pga4v4a51EzzL8vkQnrB90KSgNuA1RFxU25Wr/pOtHUcyn4neuTdVgDpNrPv8mp3JpNqnFKXk3QcWWsDsq5oftqbjoOku4FRZN1NbwauB34GzASOBtYDF0dEj76Y3MZxGEV2eiKAdcCnc+f9eyRJI4F/A5YDe1L4y2Tn+3vNd6Kd43AZJb4TPbZ4mJlZdXrqaSszM6uQi4eZmZXm4mFmZqW5eJiZWWkuHmZmVpqLh3V7kl6sYJvD8r2Kph5Hv7AP2/uIpNWS5ndOhnudxzpJ/WuZg/UMLh5mrRsGdGY35WOBT0XE6Z24TbOacfGwHkXSFyUtSp273ZBiDemv/qnp/QUPSDo4zTslLbtU0rclrUi9EnwduCTFL0mbP0HSQ5LWSLq6jf1flt6fskLSN1Psa8BI4DZJ326x/CBJC9N+Vkg6LcVvlbQ45XtDbvl1kr6Rll8s6WRJcyX9TtJn0jKj0jZnK3unzQ8lve7/uqSPSXosbetHkvqk4faUy3JJ/3Mf/0msp4oIDx669UD2DgLIul+ZAojsD6OfAx8AGoBdwLC03EzgY2l8BfC+ND4ZWJHGrwC+n9vHRODXwIFkT2o/C+zfIo8jgf8EBpA90f8r4II07yGy96q0zP1a4CtpvA9wWBrvl4s9BLwrTa8DPpvGbwaWAYelfW5O8VHAH4Hj0vrzgIty6/cH3g783+afAfgn4HLgPcC8XH59a/3v66E+B7c8rCc5Kw1PAI8DbwOGpnlrI2JpGl8CNEjqS/bL+jcp/tMOtj87InZG9mKtLby+6+5TgIciYmtE7ALuIite7VkEXJlezvTOyN6vAHCxpMfTz3IicEJuneZ+2pYDj0bEjojYCuxMPxPAY5G9z2Y3cDdZyyfvDLJCsUjS0jR9HLAGOE7S9ySdA7yAWSveUOsEzDqRgG9ExI9eE8zeWbAzF9oNHLwX22+5jX3+/xMRC1M3+ecDt0u6iazfoS8Ap0TEc5JuBw5qJY89LXLak8upZb9DLacFTI+I61rmJOkk4GzgM2Rvl/tE2Z/Lej63PKwnmQt8Ir2nAEmDJb25rYUj4nlgh6RTU+jS3OwdZKeDyngM+KCk/spehXwZsKC9FSQdQ3a6aSrwz8DJwBuBl4DtkgaSvYulrBGpV+n9gEuAh1vMfxC4qPn4KHuP9zHpTqz9IuIe4KspH7PXccvDeoyIeEDS24HfZL1O8yLwMbJWQlvGAlMl7SH7Rb89xecDE9IpnW8U3P8mZe/Ank/2l/3siOioe+9RwBclvZLyvTwi1kp6Avgt2Rsx/73I/ltYBHwfOD7lc19+ZkSskvRVsrdM7ge8AowH/gD8OHeB/XUtEzNwr7rWy0k6NCJeTOMTgEERcU2N09onkkYBX4iID9c6F+u53PKw3u58SdeR/V9YT3aXlZl1wC0PMzMrzRfMzcysNBcPMzMrzcXDzMxKc/EwM7PSXDzMzKy0/w+mVWnjcK+yaQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 10"
      ],
      "metadata": {
        "id": "tXTj1edfPFWR"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작토큰과 종료토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 10이하인 경우만 데이터셋으로 허용, 두개의 토큰이 붙었으므로 최대길이는 +2\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 최대길이 10으로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
        "  )\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
        "  )\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "metadata": {
        "id": "gfh1H2y4PPU1"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수 인코딩 과정을 수행하면서 샘플의 길이가 10을 넘는 경우는 샘플들을 필터링하였으므로 일부 샘플이 제외되었습니다. 단어장의 크기와 샘플의 개수를 확인해보겠습니다."
      ],
      "metadata": {
        "id": "ZO6DsoTrSEPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어장의 크기:', (VOCAB_SIZE))\n",
        "print('필터링 후의 질문샘플개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변샘플개수: {}'.format(len(answers)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXiE8c59SNZA",
        "outputId": "99ea3b84-5a87-4f93-ada5-bf4e7320f354"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기: 10108\n",
            "필터링 후의 질문샘플개수: 9584\n",
            "필터링 후의 답변샘플개수: 9584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions[3], answers[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LFNeI8CSv21",
        "outputId": "9f635291-b9bc-4327-febb-cd657cfbf645"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([10106,  9901,  1094,  4033,  9882,  1146,  3178,    62, 10107,\n",
              "            0], dtype=int32),\n",
              " array([10106,  2958,   688,   121,     1, 10107,     0,     0,     0,\n",
              "            0], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 교사강요 사용하기\n",
        "트랜스포머 디코더에서도 교사강요를 적용합니다."
      ],
      "metadata": {
        "id": "9-hLiGTjUICe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 3000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "n4NbeoDcgwjR"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step4. 모델정의 및 학습하기\n",
        "트랜스포머 함수에 사용할 인코더와 디코더를 먼저 정의해주겠습니다."
      ],
      "metadata": {
        "id": "uR7C0aoVoGv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "\n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "vuhJRMSxqw2Q"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 트랜스포머 함수를 정의해봅시다."
      ],
      "metadata": {
        "id": "mJ5KagGsrmX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "xHToqZpKrp9b"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 생성"
      ],
      "metadata": {
        "id": "TG7mknZtr0dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.4 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLm0StDyr-88",
        "outputId": "b3f3dd3e-e8a5-4676-9031-ff75004fc538"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    11487232    ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    15693824    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10108)  5185404     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,366,460\n",
            "Trainable params: 32,366,460\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실함수\n",
        "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할때 패딩 마스크를 적용해야 합니다."
      ],
      "metadata": {
        "id": "6_o-hquus79G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "gsoQrF_ztBlT"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 커스텀 된 학습률(Learning rate)\n",
        "최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다."
      ],
      "metadata": {
        "id": "hF4B2JbvtOM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "MXY1XKWotce6"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 컴파일\n",
        "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일합니다."
      ],
      "metadata": {
        "id": "GDg4Sq2YugRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "IqBdNN1aujc0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련하기"
      ],
      "metadata": {
        "id": "_0sqTrClus3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 150\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqJSkCZzuviP",
        "outputId": "d5322299-a259-42ae-f647-493bad82fda0"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "300/300 [==============================] - 16s 52ms/step - loss: 2.6238 - accuracy: 0.2604\n",
            "Epoch 2/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.5756 - accuracy: 0.2627\n",
            "Epoch 3/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.5289 - accuracy: 0.2653\n",
            "Epoch 4/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.4821 - accuracy: 0.2685\n",
            "Epoch 5/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.4349 - accuracy: 0.2715\n",
            "Epoch 6/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.3999 - accuracy: 0.2724\n",
            "Epoch 7/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 2.3503 - accuracy: 0.2767\n",
            "Epoch 8/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.3213 - accuracy: 0.2789\n",
            "Epoch 9/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.2761 - accuracy: 0.2826\n",
            "Epoch 10/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.2368 - accuracy: 0.2857\n",
            "Epoch 11/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.1930 - accuracy: 0.2891\n",
            "Epoch 12/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.1580 - accuracy: 0.2919\n",
            "Epoch 13/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.1266 - accuracy: 0.2946\n",
            "Epoch 14/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.1041 - accuracy: 0.2970\n",
            "Epoch 15/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 2.0700 - accuracy: 0.3005\n",
            "Epoch 16/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.0329 - accuracy: 0.3045\n",
            "Epoch 17/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 2.0105 - accuracy: 0.3077\n",
            "Epoch 18/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.9737 - accuracy: 0.3118\n",
            "Epoch 19/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.9386 - accuracy: 0.3152\n",
            "Epoch 20/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.9131 - accuracy: 0.3186\n",
            "Epoch 21/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.8864 - accuracy: 0.3216\n",
            "Epoch 22/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.8578 - accuracy: 0.3258\n",
            "Epoch 23/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.8321 - accuracy: 0.3291\n",
            "Epoch 24/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.8105 - accuracy: 0.3327\n",
            "Epoch 25/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.7832 - accuracy: 0.3358\n",
            "Epoch 26/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.7634 - accuracy: 0.3396\n",
            "Epoch 27/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.7348 - accuracy: 0.3419\n",
            "Epoch 28/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.7155 - accuracy: 0.3446\n",
            "Epoch 29/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.7043 - accuracy: 0.3480\n",
            "Epoch 30/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.6830 - accuracy: 0.3504\n",
            "Epoch 31/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.6625 - accuracy: 0.3528\n",
            "Epoch 32/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.6409 - accuracy: 0.3560\n",
            "Epoch 33/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.6308 - accuracy: 0.3572\n",
            "Epoch 34/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.6329 - accuracy: 0.3584\n",
            "Epoch 35/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.6041 - accuracy: 0.3620\n",
            "Epoch 36/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.5897 - accuracy: 0.3636\n",
            "Epoch 37/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.5682 - accuracy: 0.3686\n",
            "Epoch 38/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.5663 - accuracy: 0.3681\n",
            "Epoch 39/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.5433 - accuracy: 0.3718\n",
            "Epoch 40/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.5315 - accuracy: 0.3737\n",
            "Epoch 41/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.5140 - accuracy: 0.3764\n",
            "Epoch 42/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.5091 - accuracy: 0.3779\n",
            "Epoch 43/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.4872 - accuracy: 0.3816\n",
            "Epoch 44/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4782 - accuracy: 0.3832\n",
            "Epoch 45/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4684 - accuracy: 0.3854\n",
            "Epoch 46/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4582 - accuracy: 0.3870\n",
            "Epoch 47/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4441 - accuracy: 0.3885\n",
            "Epoch 48/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4273 - accuracy: 0.3920\n",
            "Epoch 49/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4260 - accuracy: 0.3921\n",
            "Epoch 50/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4119 - accuracy: 0.3946\n",
            "Epoch 51/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.4069 - accuracy: 0.3955\n",
            "Epoch 52/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.3964 - accuracy: 0.3974\n",
            "Epoch 53/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3841 - accuracy: 0.3995\n",
            "Epoch 54/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3707 - accuracy: 0.4017\n",
            "Epoch 55/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3668 - accuracy: 0.4028\n",
            "Epoch 56/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3581 - accuracy: 0.4036\n",
            "Epoch 57/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.3496 - accuracy: 0.4055\n",
            "Epoch 58/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3404 - accuracy: 0.4077\n",
            "Epoch 59/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3331 - accuracy: 0.4086\n",
            "Epoch 60/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3211 - accuracy: 0.4106\n",
            "Epoch 61/150\n",
            "300/300 [==============================] - 15s 49ms/step - loss: 1.3176 - accuracy: 0.4112\n",
            "Epoch 62/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.3141 - accuracy: 0.4126\n",
            "Epoch 63/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.3060 - accuracy: 0.4139\n",
            "Epoch 64/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2961 - accuracy: 0.4168\n",
            "Epoch 65/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.2889 - accuracy: 0.4165\n",
            "Epoch 66/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.2777 - accuracy: 0.4203\n",
            "Epoch 67/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2704 - accuracy: 0.4209\n",
            "Epoch 68/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.2703 - accuracy: 0.4210\n",
            "Epoch 69/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.2611 - accuracy: 0.4217\n",
            "Epoch 70/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2533 - accuracy: 0.4234\n",
            "Epoch 71/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.2505 - accuracy: 0.4241\n",
            "Epoch 72/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2382 - accuracy: 0.4266\n",
            "Epoch 73/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2368 - accuracy: 0.4268\n",
            "Epoch 74/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2286 - accuracy: 0.4275\n",
            "Epoch 75/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2343 - accuracy: 0.4282\n",
            "Epoch 76/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2270 - accuracy: 0.4297\n",
            "Epoch 77/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.2128 - accuracy: 0.4316\n",
            "Epoch 78/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2097 - accuracy: 0.4322\n",
            "Epoch 79/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2052 - accuracy: 0.4323\n",
            "Epoch 80/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.2078 - accuracy: 0.4313\n",
            "Epoch 81/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1991 - accuracy: 0.4351\n",
            "Epoch 82/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1966 - accuracy: 0.4356\n",
            "Epoch 83/150\n",
            "300/300 [==============================] - 16s 52ms/step - loss: 1.1857 - accuracy: 0.4366\n",
            "Epoch 84/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1817 - accuracy: 0.4382\n",
            "Epoch 85/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1770 - accuracy: 0.4385\n",
            "Epoch 86/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1781 - accuracy: 0.4383\n",
            "Epoch 87/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1679 - accuracy: 0.4403\n",
            "Epoch 88/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1654 - accuracy: 0.4404\n",
            "Epoch 89/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1643 - accuracy: 0.4405\n",
            "Epoch 90/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1568 - accuracy: 0.4422\n",
            "Epoch 91/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1513 - accuracy: 0.4431\n",
            "Epoch 92/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1540 - accuracy: 0.4432\n",
            "Epoch 93/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1452 - accuracy: 0.4450\n",
            "Epoch 94/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1403 - accuracy: 0.4470\n",
            "Epoch 95/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1391 - accuracy: 0.4461\n",
            "Epoch 96/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1359 - accuracy: 0.4464\n",
            "Epoch 97/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1377 - accuracy: 0.4479\n",
            "Epoch 98/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1322 - accuracy: 0.4475\n",
            "Epoch 99/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1303 - accuracy: 0.4478\n",
            "Epoch 100/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1222 - accuracy: 0.4499\n",
            "Epoch 101/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1189 - accuracy: 0.4496\n",
            "Epoch 102/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1156 - accuracy: 0.4515\n",
            "Epoch 103/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1168 - accuracy: 0.4510\n",
            "Epoch 104/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1136 - accuracy: 0.4523\n",
            "Epoch 105/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.1030 - accuracy: 0.4533\n",
            "Epoch 106/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0971 - accuracy: 0.4547\n",
            "Epoch 107/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.1029 - accuracy: 0.4535\n",
            "Epoch 108/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0921 - accuracy: 0.4560\n",
            "Epoch 109/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0958 - accuracy: 0.4550\n",
            "Epoch 110/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0874 - accuracy: 0.4562\n",
            "Epoch 111/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0865 - accuracy: 0.4570\n",
            "Epoch 112/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0834 - accuracy: 0.4572\n",
            "Epoch 113/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0816 - accuracy: 0.4579\n",
            "Epoch 114/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0739 - accuracy: 0.4594\n",
            "Epoch 115/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0732 - accuracy: 0.4597\n",
            "Epoch 116/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0727 - accuracy: 0.4585\n",
            "Epoch 117/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0734 - accuracy: 0.4585\n",
            "Epoch 118/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0663 - accuracy: 0.4600\n",
            "Epoch 119/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0689 - accuracy: 0.4595\n",
            "Epoch 120/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0602 - accuracy: 0.4606\n",
            "Epoch 121/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0641 - accuracy: 0.4615\n",
            "Epoch 122/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0535 - accuracy: 0.4617\n",
            "Epoch 123/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0532 - accuracy: 0.4619\n",
            "Epoch 124/150\n",
            "300/300 [==============================] - 15s 52ms/step - loss: 1.0517 - accuracy: 0.4637\n",
            "Epoch 125/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0440 - accuracy: 0.4644\n",
            "Epoch 126/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0425 - accuracy: 0.4651\n",
            "Epoch 127/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0434 - accuracy: 0.4644\n",
            "Epoch 128/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0380 - accuracy: 0.4659\n",
            "Epoch 129/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0358 - accuracy: 0.4654\n",
            "Epoch 130/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0355 - accuracy: 0.4663\n",
            "Epoch 131/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0275 - accuracy: 0.4687\n",
            "Epoch 132/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0312 - accuracy: 0.4664\n",
            "Epoch 133/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0276 - accuracy: 0.4673\n",
            "Epoch 134/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0175 - accuracy: 0.4694\n",
            "Epoch 135/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0215 - accuracy: 0.4686\n",
            "Epoch 136/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0180 - accuracy: 0.4701\n",
            "Epoch 137/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0172 - accuracy: 0.4693\n",
            "Epoch 138/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0122 - accuracy: 0.4697\n",
            "Epoch 139/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0120 - accuracy: 0.4706\n",
            "Epoch 140/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 1.0110 - accuracy: 0.4704\n",
            "Epoch 141/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0096 - accuracy: 0.4710\n",
            "Epoch 142/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 1.0004 - accuracy: 0.4725\n",
            "Epoch 143/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 0.9995 - accuracy: 0.4721\n",
            "Epoch 144/150\n",
            "300/300 [==============================] - 16s 52ms/step - loss: 1.0005 - accuracy: 0.4718\n",
            "Epoch 145/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 0.9941 - accuracy: 0.4738\n",
            "Epoch 146/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 0.9941 - accuracy: 0.4737\n",
            "Epoch 147/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 0.9947 - accuracy: 0.4726\n",
            "Epoch 148/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 0.9860 - accuracy: 0.4756\n",
            "Epoch 149/150\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 0.9849 - accuracy: 0.4757\n",
            "Epoch 150/150\n",
            "300/300 [==============================] - 15s 51ms/step - loss: 0.9829 - accuracy: 0.4747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa7daff8d90>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5. 모델 평가하기\n",
        "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
        "\n",
        "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
        "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
        "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
        "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
        "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
        "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
        "\n",
        "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다.\n"
      ],
      "metadata": {
        "id": "3IqbYqnNw61s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ],
      "metadata": {
        "id": "pWkbbMoNxPan"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
      ],
      "metadata": {
        "id": "rBgIkAe3xWz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "GnZdPVeuxXej"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('나 배고파')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjWwto4exbTE",
        "outputId": "68d78f0e-2a1a-48e9-a837-6ab7812046d5"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 나 배고파\n",
            "출력 : 얼른 집에 가서 쉬시길 바랄게요 . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('공부하기싫어')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j2Hj02I8NEQ",
        "outputId": "5b379523-ccb5-411a-a8de-2e3a4895dc54"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 공부하기싫어\n",
            "출력 : 물 마시세요 . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('나 물 싫어해')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wASXxrS8m91",
        "outputId": "a2954566-c8a6-4638-ea02-b18f8a7b1f5c"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 나 물 싫어해\n",
            "출력 : 회사 근처로 이사를 가보세요 . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('나 회사 안다니고 지금 학생인데')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3FWpMcq8q9z",
        "outputId": "1cc38d73-a9c7-4b3a-81c8-276bea69d506"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 나 회사 안다니고 지금 학생인데\n",
            "출력 : 이제 더 이상 보지 마세요 . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('애플 vs 갤럭시')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "albb519383ig",
        "outputId": "00e106e3-bcf8-4d3f-f7c1-5957ad8c1cc4"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 애플 vs 갤럭시\n",
            "출력 : 직접 물어보세요 . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "- 트랜스포머 구조를 잘 이해했다고 생각했지만 막상 코드를 써보니 너무 길고 복잡했다..\n",
        "- 모델초기에 학습률이 높았다가, 스텝이 커질수록 학습률을 줄여나가는 커스텀 학습률 스케줄링기법을 배웠다\n",
        "- 테스트로 여러 문장을 입력 시켜봤다. 생각하기에따라 대답을 잘 했다고 어거지로 볼 수 있지만, 그래도 문맥에 딱 맞는 대답은 하지 못해보인다.\n",
        " "
      ],
      "metadata": {
        "id": "5lq3LLLl9elN"
      }
    }
  ]
}